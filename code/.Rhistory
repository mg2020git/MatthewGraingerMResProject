file.func = "../data/20151016_Functions_remainder.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
select.class = select.func
# --- Reshaping data parameters
nreads = 10000 # minimum number of reads to consider a sample
exclude_exp = c("4M") # A vector of characters with the experiments that should be excluded
match_exp = TRUE # Set to true if only starting communities that were resurrected should be included
output.label = "Time0D_7D_matched"
# READING INPUT FILES
# ASV Table
ASV.table=read.table(file = file.ASV, sep="\t")
# Metadata
sample_md <-read.table(file = file.Meta, sep="\t", header=TRUE)
# Function data
data.func <- read.csv(file = file.func)
# Cluster data
cluster_data <- read.csv(file = file.cluster, sep = "\t")
# CLEANING DATA - Removing experiment 4M, keeping only final samples, and only keeping samples present in the metadata
clean.data.list = clean_ASV_table(ASV.table ,sample_md , match_exp = TRUE, exclude_exp = c("4M"),
nreads = 10000) # Outputs list containing cleaned asv table and meta data
ASV.table = clean.data.list$ASV.table
sample_md = clean.data.list$sample_md
##### BUILDING REGRESSION DATA #####
## Modifying ASV table
# Keeping only final communities
id.t7 = grep("7D", sample_md$Experiment) # Indices of rows whcih are final communities
samples.t7 = as.character(sample_md$sampleid[id.t7]) # Sampleids of final communities
xIn.tmp = ASV.table[samples.t7, ] # ASV table containing only final communities
# Transposing asv table for merging
xIn.tmp <- t(xIn.tmp) # Transposing ASV table so that there is one column with all ASVs
xIn.tmp <- as.data.frame(xIn.tmp) # Making back into data frame type object
xIn.tmp$ASV = rownames(xIn.tmp) # Making ASV column from row names
rownames(xIn.tmp) = seq(1,dim(xIn.tmp)[1]) # Row names are now numbers
xIn.tmp = xIn.tmp[,c(dim(xIn.tmp)[2],1:(dim(xIn.tmp)[2]-1))] # reorder so that the first column is ASV
# Preparing cluster data for merging
cluster_data = cluster_data[,1:2] # Getting rid of 'set' column
cluster_counts <- table(cluster_data$functionInk) # Sizes of each cluster
cluster_data <- cluster_data[cluster_data$functionInk %in% names(cluster_counts[cluster_counts >= 2]), ]
# Merging
xIn.tmp = merge(xIn.tmp, cluster_data, by = "ASV", all.x = FALSE) # Merging wiht cluster data by ASV
xIn.tmp <- xIn.tmp[, -1] # Get rid of ASV column
xIn.tmp <- xIn.tmp %>%
group_by(functionInk) %>%
summarize(across(everything(), \(x) sum(x, na.rm = TRUE)), .groups = 'drop')
# Transposing back
xIn.tmp <- t(xIn.tmp)
xIn.tmp <- as.data.frame(xIn.tmp) # Making back into data frame type object
colnames(xIn.tmp) <- as.character(unlist(xIn.tmp[1, ])) # first row as colnames
xIn.tmp <- xIn.tmp[-1, ] # Remove the first row from the data frame
# Adding column with the logarithm of the number of reads in each sample
xIn.tmp$counts = rowSums(xIn.tmp[,-1]) # add the sum of the counts for each sample as an additional predictor
xIn.tmp$counts = log(xIn.tmp$counts) # log it to avoid having too high numbers
# Splitting into 1df for training (rep1 samples) and 1df for testing (rep2,3,4 samples)
id.rep1 = grep("Rep1", sample_md$replicate) # Indices of rows which are rep1 communities
samples.rep1 = as.character(sample_md$sampleid[id.rep1]) # Sampleids of rep1 communities
xIn.train <- xIn.tmp[samples.rep1, ] # ASV table containing only rep1 communities
id.rep234 = sample_md$replicate %in% c("Rep2", "Rep3", "Rep4") # Indices of rep2,3,4
samples.rep234 = as.character(sample_md$sampleid[id.rep234]) # samples ids rep2,3,4
xIn.test <- xIn.tmp[samples.rep234, ] # Only rep2,3,4 communities
# create a new column for sampleid
xIn.train$sampleid = rownames(xIn.train)
xIn.test$sampleid = rownames(xIn.test)
# Formatting
rownames(xIn.train) = seq(1,dim(xIn.train)[1]) # Row names are now numbers
xIn.train = xIn.train[,c(dim(xIn.train)[2],1:(dim(xIn.train)[2]-1))] # reorder so that the first column is sampleid
rownames(xIn.test) = seq(1,dim(xIn.test)[1]) # Row names are now numbers
xIn.test = xIn.test[,c(dim(xIn.test)[2],1:(dim(xIn.test)[2]-1))] # reorder so that the first column is sampleid
## Modifying function data
# Changing units
data.func$mgCO2.7 <- data.func$mgCO2.7 * 1000 # Converting CO2 from miligr. to microgr.
names(data.func)[names(data.func) == "mgCO2.7"] <- "μgCO2.7" # Changing column name accordingly
data.func$ATP7 <- data.func$ATP7 / 1000 # Changing nanomolar to micromolar
data.func$ATP14 <- data.func$ATP14 / 1000
# Normalising by number of cells
data.func$ATP7.norm <- data.func$ATP7 / data.func$CPM7
data.func$mG7.norm <- data.func$mG7 / data.func$CPM7
data.func$mN7.norm <- data.func$mN7 / data.func$CPM7
data.func$mX7.norm <- data.func$mX7 / data.func$CPM7
data.func$mP7.norm <- data.func$mP7 / data.func$CPM7
data.func$μgCO2.7.norm <- data.func$μgCO2.7 / data.func$CPM7
# Taking log of normalised functions and cell count
data.func$log.ATP7.norm <- log(data.func$ATP7.norm + 0.00001)
data.func$log.mG7.norm <- log(data.func$mG7.norm + 0.00001)
data.func$log.mN7.norm <- log(data.func$mN7.norm + 0.00001)
data.func$log.mX7.norm <- log(data.func$mX7.norm + 0.00001)
data.func$log.mP7.norm <- log(data.func$mP7.norm + 0.00001)
data.func$log.μgCO2.7.norm <- log(data.func$μgCO2.7.norm + 0.00001)
# Selecting only the function and condition of interest e.g. ATP7
functions.list <- colnames(data.func) # Columns in function data
data.func.x <- data.frame(data.func[,grep(select.func, functions.list), drop = FALSE]) # Dataframe with only selected function
functions.list <- colnames(data.func.x) # Functions of interest with different conditions e.g. ATP7 and ATP14
data.func.x <- data.func.x[,grep(select.cond, functions.list), drop = FALSE] # Selects only the chosen condition e.g. ATP7
# data.func.x has only the chosen function and condition e.g. ATP7
data.func.x$sampleid <- paste0(data.func$Community, ".", data.func$Replicate) # adding sampleid column to data.func.x
# Splitting function data for the training (rep1) and testing (rep2,3,4) data
sample.id.train <- intersect(data.func.x$sampleid, xIn.train$sampleid)  # The sampleid of samples in the function data and the training data
sample.id.test <- intersect(data.func.x$sampleid, xIn.test$sampleid) # The sampleid of samples in the function data and the testing data
data.func.x.train <- data.func.x[data.func.x$sampleid %in% sample.id.train, ] # Only keeping samples in both the training data and the function data
data.func.x.test <- data.func.x[data.func.x$sampleid %in% sample.id.test, ] # Only keeping samples in both the testing data and the function data
xIn.train <- xIn.train[xIn.train$sampleid %in% sample.id.train, ] # Only keeping sampleids that are in both the function data and the training data
xIn.train <- xIn.train[order(xIn.train$sampleid), ] # Sorting so in same order as function data
data.func.x.train <- data.func.x.train[order(data.func.x.train$sampleid), ] # sorting so in same order as training data
xIn.test <- xIn.test[xIn.test$sampleid %in% sample.id.test, ] # Only keeping sampleids that are in both the function data and the testing data
xIn.test <- xIn.test[order(xIn.test$sampleid), ] # Sorting so in same order as function data
data.func.x.test <- data.func.x.test[order(data.func.x.test$sampleid), ] # sorting so in same order as testing data
xIn.train <- data.frame(xIn.train[, -which(names(xIn.train) == "sampleid")], check.names = FALSE) # get rid of sampleid column from training data
xIn.test <- data.frame(xIn.test[, -which(names(xIn.test) == "sampleid")], check.names = FALSE) # get rid of sampleid column from testing data
View(xIn.train)
data.func.x.train <- data.func.x.train[, -which(names(data.func.x.train) == "sampleid")] # get rid of sampleid column from function data
data.func.x.test <- data.func.x.test[, -which(names(data.func.x.test) == "sampleid")] # get rid of sampleid column from function data
yIn.train = as.numeric(data.func.x.train) # response vector training
yIn.test = as.numeric(data.func.x.test) # response vector testing
## NOTE: Using replicate 1 communities for training, rep 2, 3, 4 for predicting ##
readRDS("/rds/general/user/mg2020/home/researchprojecthpc/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
readRDS("../results/Optimised_ATP7_Cluster/OPTIMALRF_Class-log.ATP7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/Optimised_XYLO7_Cluster/OPTIMALRF_Class-log.ATP7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/Optimised_XYLO7_Cluster/OPTIMALRF_Class-log.mC7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/Optimised_XYLO7_Cluster/OPTIMALRF_Class-log.mX7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/Optimised_XYLO7_ASV/OPTIMALRF_Class-log.mX7.norm_ASV_AllRepTrain.RDS")
getwd()
setwd(../code)
setwd("../code")
getwd()
RF.out <- readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
# Random forest explanation (overview)
fileOut=paste("../results/", "OptimalRFExplained-", "ATP7_ASV_AllRep",
".html",sep="") # Name of file
explain_forest(RF.out, path = fileOut)
getwd()
# Reading in RF model
RF.out <- readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
# Random forest explanation (overview)
fileOut=paste("../results/Optimised_ATP7_ASV/", "OptimalRFExplained-", "ATP7_ASV_AllRep",
".html",sep="") # Name of file
explain_forest(RF.out, path = fileOut)
getwd()
# Reading in RF model
RF.out <- readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
# Random forest explanation (overview)
fileOut=paste("OptimalRFExplained-", "ATP7_ASV_AllRep",
".html",sep="") # Name of file
explain_forest(RF.out, path = fileOut)
getwd()
# Loading packages
library(randomForest)
library(randomForestExplainer)
# Reading in RF model
RF.out <- readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
# Random forest explanation (overview)
fileOut=paste("OptimalRFExplained_ATP7_ASV_AllRep.html",sep="") # Name of file
explain_forest(RF.out, path = fileOut)
# Loading packages
library(randomForest)
library(randomForestExplainer)
# Reading in RF model
RF.out <- readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
View(RF.out)
getwd()
# Loading packages
library(randomForest)
library(randomForestExplainer)
# Reading in RF model
RF.out <- readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
# Random forest explanation (overview)
fileOut=paste("OptimalRFExplained_ATP7_ASV_AllRep.html") # Name of file
explain_forest(RF.out, path = fileOut)
library(dplyr)
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
View(cluster_data)
# Get number of ASVs in each cluster
# Sample random ASV without replacement from ASV list
library(dplyr)
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
counted_names <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
print(counted_names)
View(counted_names)
View(cluster_data)
#### Bootstrapping to find out if clusters important
#
# Get number of ASVs in each cluster
# Sample random ASV without replacement from ASV list
library(dplyr)
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
ASV_list <- colnames(ASV.table)
ASV_list
View(counted_clusters)
#### Bootstrapping to find out if clusters important
#
# Get number of ASVs in each cluster
# Sample random ASV without replacement from ASV list
library(dplyr)
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
ASV_list <- colnames(ASV.table)
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = cluster)
}
cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- name_df$Number[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
cluster_data <- bind_rows(cluster_data, sampled_df)
}
#### Bootstrapping to find out if clusters important
#
# Get number of ASVs in each cluster
# Sample random ASV without replacement from ASV list
library(dplyr)
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
ASV_list <- colnames(ASV.table)
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = cluster)
}
cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
cluster_data <- bind_rows(cluster_data, sampled_df)
}
#### Bootstrapping to find out if clusters important
#
# Get number of ASVs in each cluster
# Sample random ASV without replacement from ASV list
library(dplyr)
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
ASV_list <- colnames(ASV.table)
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = as.character(cluster))
}
cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
cluster_data <- bind_rows(cluster_data, sampled_df)
}
View(cluster_data)
# Loading packages
library(dplyr)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
# Counting size of each cluster (number of ASVs in it)
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
# Ensuing cluster column is character
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
# List of all ASVs
ASV_list <- colnames(ASV.table)
# Function that samples a given number of ASVs from an ASV pool
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = as.character(cluster))
}
# New cluster data data frame in same format as original
new_cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
# Looping over each cluster and sampling a new set of random ASVs to place them within it
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
new_cluster_data <- bind_rows(new_cluster_data, sampled_df)
}
View(new_cluster_data)
# Loading packages
library(dplyr)
# Setting seed
set.seed(250724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
# Counting size of each cluster (number of ASVs in it)
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
# Ensuing cluster column is character
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
# List of all ASVs
ASV_list <- colnames(ASV.table)
# Function that samples a given number of ASVs from an ASV pool
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = as.character(cluster))
}
# New cluster data data frame in same format as original
new_cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
# Looping over each cluster and sampling a new set of random ASVs to place them within it
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
new_cluster_data <- bind_rows(new_cluster_data, sampled_df)
}
View(new_cluster_data)
# Loading packages
library(dplyr)
# Setting seed
set.seed(250724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
# Counting size of each cluster (number of ASVs in it)
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
# Ensuing cluster column is character
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
# List of all ASVs
ASV_list <- colnames(ASV.table)
# Function that samples a given number of ASVs from an ASV pool
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = as.character(cluster))
}
# New cluster data data frame in same format as original
new_cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
# Looping over each cluster and sampling a new set of random ASVs to place them within it
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
new_cluster_data <- bind_rows(new_cluster_data, sampled_df)
}
# Loading packages
library(dplyr)
# Setting seed
set.seed(250724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
# Counting size of each cluster (number of ASVs in it)
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
# Ensuing cluster column is character
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
# List of all ASVs
ASV_list <- colnames(ASV.table)
# Function that samples a given number of ASVs from an ASV pool
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = as.character(cluster))
}
# New cluster data data frame in same format as original
new_cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
# Looping over each cluster and sampling a new set of random ASVs to place them within it
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
new_cluster_data <- bind_rows(new_cluster_data, sampled_df)
}
View(new_cluster_data)
# Loading packages
library(dplyr)
# Setting seed
set.seed(260724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
# Counting size of each cluster (number of ASVs in it)
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
# Ensuing cluster column is character
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
# List of all ASVs
ASV_list <- colnames(ASV.table)
# Function that samples a given number of ASVs from an ASV pool
sample_asvs <- function(cluster, size, asv_pool) {
sampled_asvs <- sample(asv_pool, size, replace = FALSE)
data.frame(ASV = sampled_asvs, functionInk = as.character(cluster))
}
# New cluster data data frame in same format as original
new_cluster_data <- data.frame(ASV = character(), functionInk = character(), stringsAsFactors = FALSE)
# Looping over each cluster and sampling a new set of random ASVs to place them within it
for (i in 1:nrow(counted_clusters)) {
cluster <- counted_clusters$functionInk[i]
size <- counted_clusters$Count[i]
sampled_df <- sample_asvs(cluster, size, ASV_list)
# Remove the sampled ASVs from the pool to avoid replacement
ASV_list <- setdiff(ASV_list, sampled_df$ASV)
# Append the sampled data to the result data frame
new_cluster_data <- bind_rows(new_cluster_data, sampled_df)
}
View(new_cluster_data)
sum(counted_clusters$Count)
length(ASV_list)
# Loading packages
library(dplyr)
# Setting seed
set.seed(260724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
# Counting size of each cluster (number of ASVs in it)
counted_clusters <- cluster_data %>%
count(functionInk) %>%
rename(Count = n)
# Ensuing cluster column is character
counted_clusters$functionInk <- as.character(counted_clusters$functionInk)
# List of all ASVs
ASV_list <- colnames(ASV.table)
sum(counted_clusters$Count)
length(ASV_list)
# Loading packages
library(dplyr)
# Setting seed
set.seed(260724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
shuffled_clusters <- sample(cluster_data$functionInk)
shuffled_ASVs <- sample(cluster_data$ASV)
cluster_data <- data.frame(ASV = shuffled_ASVs, functionInk = shuffled_ASVs)
View(cluster_data)
cluster_data <- data.frame(ASV = shuffled_ASVs, functionInk = shuffled_clusters)
View(cluster_data)
# Loading packages
library(dplyr)
# Setting seed
set.seed(260724)
# Importing data
file.ASV = "../data/seqtable_readyforanalysis.csv"
file.cluster = "../data/max_tot_ext_network_table.tsv"
cluster_data <- read.csv(file = file.cluster, sep = "\t")
ASV.table=read.table(file = file.ASV, sep="\t")
View(cluster_data)
shuffled_clusters <- sample(cluster_data$functionInk)
shuffled_ASVs <- sample(cluster_data$ASV)
cluster_data <- data.frame(ASV = shuffled_ASVs, functionInk = shuffled_clusters)
View(cluster_data)
readRDS("../results/Optimised_ATP7_ASV/OPTIMALRF_Class-log.ATP7.norm_ASV_AllRepTrain.RDS")
readRDS("../results/Optimised_ATP7_Cluster/OPTIMALRF_Class-log.ATP7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/Optimised_XYLO7_ASV/OPTIMALRF_Class-log.mX7.norm_ASV_AllRepTrain.RDS")
readRDS("../results/Optimised_XYLO7_Cluster/OPTIMALRF_Class-log.mX7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/RandomisedRF_ATP7_Cluster/RANDOMRF_Class-log.ATP7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/RandomisedRF_XYLO7_Cluster/RANDOMRF_Class-log.mX7.norm_Cluster_AllRepTrain.RDS")
readRDS("../results/PredictabilityRF_ATP7_ASV/OPTIMALTRAINED_Class-log.ATP7.norm_ASV_Split.RDS")
readRDS("../results/PredictabilityRF_XYLO7_ASV/OPTIMALTRAINED_Class-log.mX7.norm_ASV_Split.RDS")
readRDS("../results/PredictabilityRF_XYLO7_Cluster/OPTIMALTRAINED_Class-log.mX7.norm_Cluster_Split.RDS")
readRDS("../results/PredictabilityRF_ATP7_Cluster/OPTIMALTRAINED_Class-log.ATP7.norm_Cluster_Split.RDS")
